{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5657824,"sourceType":"datasetVersion","datasetId":3250864}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install pyspark","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-08T16:23:14.372939Z","iopub.execute_input":"2024-05-08T16:23:14.373271Z","iopub.status.idle":"2024-05-08T16:24:00.474315Z","shell.execute_reply.started":"2024-05-08T16:23:14.373232Z","shell.execute_reply":"2024-05-08T16:24:00.473149Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pyspark\n  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\nBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488493 sha256=f8ada662042cf4b5a22ecc5f030533c55425db812fbf7f4c8721ff77562cb0a7\n  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\nSuccessfully built pyspark\nInstalling collected packages: pyspark\nSuccessfully installed pyspark-3.5.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from pyspark.sql import SparkSession\nfrom pyspark.sql.types import StructType, StructField, StringType, TimestampType, ArrayType\nfrom pyspark.sql.functions import col, udf\nimport pandas as pd\nimport re\nimport spacy","metadata":{"execution":{"iopub.status.busy":"2024-05-08T16:24:00.476948Z","iopub.execute_input":"2024-05-08T16:24:00.477360Z","iopub.status.idle":"2024-05-08T16:24:06.960551Z","shell.execute_reply.started":"2024-05-08T16:24:00.477321Z","shell.execute_reply":"2024-05-08T16:24:06.959231Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\nspark","metadata":{"execution":{"iopub.status.busy":"2024-05-08T16:24:06.962354Z","iopub.execute_input":"2024-05-08T16:24:06.962808Z","iopub.status.idle":"2024-05-08T16:24:12.441021Z","shell.execute_reply.started":"2024-05-08T16:24:06.962774Z","shell.execute_reply":"2024-05-08T16:24:12.439981Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n24/05/08 16:24:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<pyspark.sql.session.SparkSession at 0x7f7b484bad10>","text/html":"\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://a5f2c307370d:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.5.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>pyspark-shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "},"metadata":{}}]},{"cell_type":"code","source":"def read_json_data_with_schema(spark, file_path, schema):\n    \"\"\"\n    Read JSON data into a DataFrame using the defined schema.\n    \n    Args:\n    - spark: SparkSession object\n    - file_path: Path to the JSON file\n    - schema: StructType schema for the JSON data\n    \n    Returns:\n    - DataFrame containing the JSON data with the defined schema\n    \"\"\"\n    df = spark.read.json(file_path, schema=schema)\n    return df\n\ndef flatten_dataframe(df):\n    \"\"\"\n    Flatten the DataFrame schema by selecting specific columns and renaming them.\n    \n    Args:\n    - df: Input DataFrame\n    \n    Returns:\n    - Flattened DataFrame\n    \"\"\"\n    df_flat = df.select(\n        col(\"_id.$oid\").alias(\"id\"),\n        col(\"sourceCC\"),\n        col(\"source\"),\n        col(\"idInSource\"),\n        col(\"locationID.$oid\").alias(\"locationID\"),\n        col(\"companyID.$oid\").alias(\"companyID\"),\n        col(\"text\"),\n        col(\"html\"),\n        col(\"json.schemaOrg.@context\").alias(\"json_schemaOrg_context\"),\n        col(\"json.schemaOrg.@type\").alias(\"json_schemaOrg_type\"),\n        col(\"json.schemaOrg.title\").alias(\"json_schemaOrg_title\"),\n        col(\"json.schemaOrg.description\").alias(\"json_schemaOrg_description\"),\n        col(\"json.schemaOrg.employmentType\").alias(\"json_schemaOrg_employmentType\"),\n        col(\"json.schemaOrg.datePosted\").alias(\"json_schemaOrg_datePosted\"),\n        col(\"json.schemaOrg.hiringOrganization.@type\").alias(\"json_schemaOrg_hiringOrganization_type\"),\n        col(\"json.schemaOrg.hiringOrganization.name\").alias(\"json_schemaOrg_hiringOrganization_name\"),\n        col(\"json.schemaOrg.hiringOrganization.logo\").alias(\"json_schemaOrg_hiringOrganization_logo\"),\n        col(\"json.schemaOrg.jobLocation.@type\").alias(\"json_schemaOrg_jobLocation_type\"),\n        col(\"json.schemaOrg.jobLocation.address.@type\").alias(\"json_schemaOrg_jobLocation_address_type\"),\n        col(\"json.schemaOrg.jobLocation.address.addressLocality\").alias(\"json_schemaOrg_jobLocation_address_addressLocality\"),\n        col(\"json.schemaOrg.jobLocation.address.addressRegion\").alias(\"json_schemaOrg_jobLocation_address_addressRegion\"),\n        col(\"json.schemaOrg.jobLocation.address.addressCountry\").alias(\"json_schemaOrg_jobLocation_address_addressCountry\"),\n        col(\"locale\"),\n        col(\"position.name\").alias(\"position_name\"),\n        col(\"position.workType\").alias(\"position_workType\"),\n        col(\"position.department\").alias(\"position_department\"),\n        col(\"position.careerLevel\").alias(\"position_careerLevel\"),\n        col(\"orgAddress.companyName\").alias(\"orgAddress_companyName\"),\n        col(\"orgAddress.addressLine\").alias(\"orgAddress_addressLine\"),\n        col(\"orgAddress.formatted\").alias(\"orgAddress_formatted\"),\n        col(\"orgAddress.level\").alias(\"orgAddress_level\"),\n        col(\"orgAddress.countryCode\").alias(\"orgAddress_countryCode\"),\n        col(\"orgAddress.country\").alias(\"orgAddress_country\"),\n        col(\"orgAddress.state\").alias(\"orgAddress_state\"),\n        col(\"orgAddress.county\").alias(\"orgAddress_county\"),\n        col(\"orgAddress.city\").alias(\"orgAddress_city\"),\n        col(\"orgAddress.district\").alias(\"orgAddress_district\"),\n        col(\"orgAddress.quarter\").alias(\"orgAddress_quarter\"),\n        col(\"orgAddress.houseNumber\").alias(\"orgAddress_houseNumber\"),\n        col(\"orgCompany.sourceCC\").alias(\"orgCompany_sourceCC\"),\n        col(\"orgCompany.source\").alias(\"orgCompany_source\"),\n        col(\"orgCompany.idInSource\").alias(\"orgCompany_idInSource\"),\n        col(\"orgCompany.mergedID\").alias(\"orgCompany_mergedID\"),\n        col(\"orgCompany.nameOrg\").alias(\"orgCompany_nameOrg\"),\n        col(\"orgCompany.description\").alias(\"orgCompany_description\"),\n        col(\"orgCompany.registryID\").alias(\"orgCompany_registryID\"),\n        col(\"orgCompany.urls.aarp_us\").alias(\"orgCompany_aarp_us\"),\n        col(\"orgCompany.urls.homepage\").alias(\"orgCompany_homepage\"),\n        col(\"orgCompany.imgLogo\").alias(\"orgCompany_imgLogo\"),\n        col(\"orgCompany.imgCover\").alias(\"orgCompany_imgCover\"),\n        col(\"orgCompany.name\").alias(\"orgCompany_name\"),\n        col(\"orgCompany.url\").alias(\"orgCompany_url\"),\n        col(\"name\"),\n        col(\"url\"),\n        col(\"dateScraped.$date\").alias(\"dateScraped\"),\n        col(\"dateMerged.$date\").alias(\"dateMerged\"),\n        col(\"dateUploaded.$date\").alias(\"dateUploaded\"),\n        col(\"dateCreated.$date\").alias(\"dateCreated\"),\n        col(\"orgTags.CATEGORIES\").alias(\"orgTags_CATEGORIES\"),\n        col(\"orgTags.REQUIREMENTS\").alias(\"orgTags_REQUIREMENTS\"),\n        col(\"orgTags.SKILLS\").alias(\"orgTags_SKILLS\")\n    )\n    return df_flat\n\ndef write_df_to_csv(df, file_path):\n    \"\"\"\n    Write a Spark DataFrame to a CSV file at the specified path.\n    \n    Args:\n    - df: Spark DataFrame\n    - file_path: Path where the CSV file will be saved\n    \n    Returns:\n    - None\n    \"\"\"\n    # Convert the Spark DataFrame to Pandas DataFrame\n    pandas_df = df.toPandas()\n    \n    # Write the Pandas DataFrame to a CSV file\n    pandas_df.to_csv(file_path, index=False)\n    \n    # Print a message to confirm that the CSV file has been written\n    print(f\"DataFrame written to '{file_path}'\")\n\n    \ndef keep_columns(df, columns_to_keep):\n    \"\"\"\n    Keep only specified columns in the DataFrame and drop the rest.\n\n    Parameters:\n    - df: Input DataFrame\n    - columns_to_keep: List of column names to keep\n\n    Returns:\n    - DataFrame with only specified columns\n    \"\"\"\n    df_kept = df.select(*columns_to_keep)\n    return df_kept","metadata":{"execution":{"iopub.status.busy":"2024-05-08T16:24:12.444032Z","iopub.execute_input":"2024-05-08T16:24:12.444408Z","iopub.status.idle":"2024-05-08T16:24:12.472007Z","shell.execute_reply.started":"2024-05-08T16:24:12.444373Z","shell.execute_reply":"2024-05-08T16:24:12.470803Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Define the schema for the JSON data\nschema = StructType([\n    StructField(\"_id\", StructType([\n        StructField(\"$oid\", StringType(), True)\n    ]), True),\n    StructField(\"sourceCC\", StringType(), True),\n    StructField(\"source\", StringType(), True),\n    StructField(\"idInSource\", StringType(), True),\n    StructField(\"locationID\", StructType([\n        StructField(\"$oid\", StringType(), True)\n    ]), True),\n    StructField(\"companyID\", StructType([\n        StructField(\"$oid\", StringType(), True)\n    ]), True),\n    StructField(\"text\", StringType(), True),\n    StructField(\"html\", StringType(), True),\n    StructField(\"json\", StructType([\n        StructField(\"schemaOrg\", StructType([\n            StructField(\"@context\", StringType(), True),\n            StructField(\"@type\", StringType(), True),\n            StructField(\"title\", StringType(), True),\n            StructField(\"description\", StringType(), True),\n            StructField(\"employmentType\", StringType(), True),\n            StructField(\"datePosted\", TimestampType(), True),\n            StructField(\"hiringOrganization\", StructType([\n                StructField(\"@type\", StringType(), True),\n                StructField(\"name\", StringType(), True),\n                StructField(\"logo\", StringType(), True)\n            ]), True),\n            StructField(\"jobLocation\", StructType([\n                StructField(\"@type\", StringType(), True),\n                StructField(\"address\", StructType([\n                    StructField(\"@type\", StringType(), True),\n                    StructField(\"addressLocality\", StringType(), True),\n                    StructField(\"addressRegion\", StringType(), True),\n                    StructField(\"addressCountry\", StringType(), True)\n                ]), True)\n            ]), True)\n        ]), True)\n    ]), True),\n    StructField(\"locale\", StringType(), True),\n    StructField(\"position\", StructType([\n        StructField(\"name\", StringType(), True),\n        StructField(\"workType\", StringType(), True),\n        StructField(\"department\", StringType(), True),\n        StructField(\"careerLevel\", StringType(), True)\n    ]), True),\n    StructField(\"orgAddress\", StructType([\n        StructField(\"companyName\", StringType(), True),\n        StructField(\"addressLine\", StringType(), True),\n        StructField(\"formatted\", StringType(), True),\n        StructField(\"level\", StringType(), True),\n        StructField(\"countryCode\", StringType(), True),\n        StructField(\"country\", StringType(), True),\n        StructField(\"state\", StringType(), True),\n        StructField(\"county\", StringType(), True),\n        StructField(\"city\", StringType(), True),\n        StructField(\"district\", StringType(), True),\n        StructField(\"quarter\", StringType(), True),\n        StructField(\"houseNumber\", StringType(), True)\n    ]), True),\n    StructField(\"orgCompany\", StructType([\n        StructField(\"sourceCC\", StringType(), True),\n        StructField(\"source\", StringType(), True),\n        StructField(\"idInSource\", StringType(), True),\n        StructField(\"mergedID\", StringType(), True),\n        StructField(\"nameOrg\", StringType(), True),\n        StructField(\"description\", StringType(), True),\n        StructField(\"registryID\", StringType(), True),\n        StructField(\"urls\", StructType([\n            StructField(\"aarp_us\", StringType(), True),\n            StructField(\"homepage\", StringType(), True)\n        ]), True),\n        StructField(\"ids\", StructType([\n            StructField(\"aarp_us\", StringType(), True)\n        ]), True),\n        StructField(\"imgLogo\", StringType(), True),\n        StructField(\"imgCover\", StringType(), True),\n        StructField(\"name\", StringType(), True),\n        StructField(\"url\", StringType(), True)\n    ]), True),\n    StructField(\"name\", StringType(), True),\n    StructField(\"url\", StringType(), True),\n    StructField(\"dateScraped\", StructType([\n        StructField(\"$date\", TimestampType(), True)\n    ]), True),\n    StructField(\"dateMerged\", StructType([\n        StructField(\"$date\", TimestampType(), True)\n    ]), True),\n    StructField(\"dateUploaded\", StructType([\n        StructField(\"$date\", TimestampType(), True)\n    ]), True),\n    StructField(\"dateCreated\", StructType([\n        StructField(\"$date\", TimestampType(), True)\n    ]), True),\n    StructField(\"orgTags\", StructType([\n        StructField(\"CATEGORIES\", ArrayType(StringType()), True),\n        StructField(\"REQUIREMENTS\", ArrayType(StringType()), True),\n        StructField(\"SKILLS\", ArrayType(StringType()), True),\n    ]), True)\n])\n\ndf = read_json_data_with_schema(spark, \"/kaggle/input/us-job-postings-from-2023-05-05/techmap-jobs_us_2023-05-05.json\", schema)\n\ndf_flat = flatten_dataframe(df)\n\n# Keep only the specified columns\ncolumns_to_keep = [\n    \"id\",\n    \"sourceCC\",\n    \"source\",\n    \"text\",\n    \"html\",\n    \"locale\",\n    \"position_name\",\n    \"position_workType\",\n    \"position_careerLevel\",\n    \"position_department\",\n    \"orgAddress_addressLine\",\n    \"orgAddress_level\",\n    \"orgAddress_country\",\n    \"orgAddress_state\",\n    \"orgAddress_city\",\n    \"orgCompany_nameOrg\",\n    \"orgCompany_homepage\",\n    \"url\",\n    \"orgTags_CATEGORIES\",\n    \"orgTags_REQUIREMENTS\",\n    \"orgTags_SKILLS\",\n]\ndf_kept = keep_columns(df_flat, columns_to_keep)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T16:24:12.473438Z","iopub.execute_input":"2024-05-08T16:24:12.473721Z","iopub.status.idle":"2024-05-08T16:24:14.207173Z","shell.execute_reply.started":"2024-05-08T16:24:12.473698Z","shell.execute_reply":"2024-05-08T16:24:14.206039Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# # Count the non-empty rows in 'position_careerLevel' using isNotNull()\n# non_empty_count = df_kept.filter(col(\"position_careerLevel\").isNotNull()).count()\n\n# print(\"Count of non-empty rows in 'position_careerLevel':\", non_empty_count)\n# # output: Count of non-empty rows in 'position_careerLevel': 4806\n\n# # Get all unique values from the \"position_workType\" column\n# unique_names = df_kept.select(\"position_workType\").distinct()\n\n# # Convert the result to a list\n# unique_names_list = [row.position_workType for row in unique_names.collect()]\n\n# print(unique_names_list)\n# # output ['fulltime, permanent', 'fulltime, parttime', 'intern', 'fulltime - eligible for benefits', 'contractor', 'other', '[parttime]', 'temporary, parttime, fulltime', 'temporary', 'contract', 'seasonal', 'vollzeit', '[fulltime, parttime]', 'temp/casual', '[fulltime]', 'parttime', 'fulltime, contractor', 'fulltime', 'fulltime benefit eligible', 'parttime, fulltime', 'fulltime, contract', 'unavailable', 'permanent, parttime', 'temporary, contractor', 'parttime, permanent', 'temp-to-hire', 'freelance', 'temporary, fulltime', 'fulltime, contractor, temporary', 'temporary, parttime, fulltime, contract, internship', '[gig]', 'prn', 'parttime, freelance', 'per diem', 'apprenticeship', '[seasonal_fulltime]', 'parttime, temporary', 'prn, per diem', 'parttime, fulltime, contract', 'parttime, contract', 'internship', 'fulltime, internship', 'seasonal, fulltime', 'temporary, contract', 'parttime, internship', 'non-tenure', 'temporary, fulltime, contract, internship', 'parttime, prn', 'temporary, parttime', 'fulltime, contract, internship', 'temporary, parttime, seasonal, fulltime', 'temporary, seasonal, fulltime', 'temporary, parttime, contract', 'parttime, fulltime, internship', 'parttime, fulltime, prn', 'contractor, temporary, jobtypecontract', 'parttime, seasonal', 'temporary, parttime, seasonal', 'temporary, seasonal', 'per_diem', 'volunteer', 'temporary, fulltime, contract, per diem', 'parttime, per diem', 'fulltime, non-tenure', 'temporary, fulltime, contract', 'temporary, parttime, seasonal, fulltime, contract', 'temporary, parttime, contract, freelance', 'travel nursing', 'parttime, contract, internship', 'parttime, fulltime, contract, internship', 'temporary, travel nursing, fulltime, contract', 'temporary, parttime, fulltime, internship', 'per_diem, contractor, temporary', 'temporary, parttime, internship', 'permanent, jobtypeemployee', 'parttime, contract, per diem', 'temporary, fulltime, contractor', 'temporary, permanent, contract', 'contract, internship', 'permanent, parttime, contract', 'parttime, prn, per diem', 'parttime, seasonal, contract', None]\n\n# # Get all unique values from the \"position_careerLevel\" column\n# unique_names = df_kept.select(\"position_careerLevel\").distinct()\n\n# # Convert the result to a list\n# unique_names_list = [row.position_careerLevel for row in unique_names.collect()]\n\n# print(unique_names_list)\n# # output: \n# # ----- 120 months of experience\n# # ----- QUALIFICATION STANDARDS: (These qualifications meet or exceed NH, MA, CT and RI State specific requirements.) \n# # a. Knowledge, Skills, and Abilities: Ability to use computer for documenting services provided. Shall be fluent in the ability to communicate in the English language, both oral and written. \n# # b. Education: Must have completed the course for certified nursing assistant or have equivalent training or experience as required by State Regulation, and CPR and First Aide training as mandated by the State employed. \n# # c. Experience: Prior experience providing direct care or the equivalent in training preferred. Experience in caring for seniors with Alzheimers disease or other forms of Dementia is preferred. \n# # d. Certificates/Licenses: Current license/certification as required by State Regulation and provide copies of the documentation to the Resident Care Director or designee. \n# # e. Computer Skills: Demonstrates computer literacy and familiarity with office software, including but not limited to word processing or demonstrate the ability to learn data input.\n# # ----- Mit Berufserfahrung\n# # ----- Leader Qualifications: Experience working with youth or young adults (15-25), teaching or environmental education a plus Experience with conservation work skills or related skills preferred i.e., trail maintenance, trail construction, habitat restoration, chainsaw, carpentry, landscaping, and gardening Ability to perform manual, physical labor for up to 8 hours per day, exposed to the elements, and must occasionally lift and/or move 40 pounds or more Must be a minimum of 21 years of age Must have the ability to legally work in the US Must have a valid drivers license for 3 years and MVR that meets SCA standards Must be able to meet SCAs criminal background check standards Must have or secure housing in the program city Leader Benefits and Compensation: $800 weekly stipend Health, Dental, Vision, Retirement, PTO Leaders may receive the following training: Mental Health First Aid Trail Skill Training with Penn Trails (Independent Trail Building Organization) Carpentry Refresher Training Project Management Training Wilderness First Aid (can be provided if needed) Game of Logging Levels I and II (if not currently saw trained) Conservation Work Skills Refresher (4 Days) Leadership1957 Interested candidates should send a brief statement of interest and a current resume to young Adult Program Manager Stephen Luteran: sluteran@thesca.org https://www.thesca.org/program/young-adult/corps/pennsylvania-outdoor-corps/ SCA is an EOE dedicated to workforce diversity. For more information about SCA, visit us at www.theSCA.org\n# # ----- Controller Requirements: Position requires a bachelors degree in accounting, higher degree preferred 2 years public accounting experience preferred and at least 2 years demonstrating competent accounting experience and Excellent oral and written communication skills required Strong organization skills and attention to detail required Proficient with Microsoft Office Suite and expert in Excel, Access or VBA is a plus Operating knowledge of ERP systems, NetSuite preferred. Experience with GAAP financial statement preparation and review required General journal entry preparation and entry experience with automation skills preferred In depth understanding of accrual and cash-based accounting Motivated, ambitious and ability to work independently required Ability to learn tasks quickly and often with minimal instruction required Controller Responsibilities: Corporate Accounting _ Prepare, examine, and analyze accounting records, financial statements, or other financial reports to assess accuracy, completeness, and conformance to reporting and procedural standards Daily operations of the accounting department, include overseeing all aspects of A/P, A/R, payroll, invoicing Maintain and analyze budgets, preparing periodic reports that compare budgeted to actual costs Treasury management, including bank reconciliations and cash flow management Demonstrate and maintain ability to effectively interact with all levels throughout the organization Facilitate the closing of all general ledger accounts in a timely manner Enter journal entries for multiple entities Review and code invoices Forecast month end Net Capital utilizing budgets and trend analysis Sales and property tax filings Reporting Work closely with the owners and CFO with respect to internal and external reporting Demonstrate and apply understanding of accounting systems and reporting to facilitate sufficient reports Correctly prepare financial statements in a timely manner, including consolidation report of all entities Prepare monthly financial statement packages for the principals As required, prepare, and review ad hoc schedules and reports, responding to the owners inquiries Respond in a timely manner to auditor, banking, bonding, insurance, and vendor requests and maintain effective interactions with all Job costing, reporting, and allocations Additional Duties and Supporting CFO: Controllership duties - These make up the backward-looking part of a Controllers job. Controllership duties hold the Controller responsible for presenting and reporting accurate and timely historical financial information of the company he or she works for. Every stakeholder in the company - including shareholders, analysts, creditors, employees and other members of management - relies on the accuracy and timeliness of this information. It is imperative that the information reported by the Controller is accurate, because many decisions are based on it. Treasury duties The Controller is also responsible for the helping CFO with company's present financial condition, so he or she may help decide how to invest the company's money, taking into consideration riskand liquidity. In addition, the Controller helps oversees the capital structureof the company, determining the best mix of debt, equityand internal financing. Addressing the issues surrounding capital structureis one of the most important duties of a Controller. Economic strategy and forecasting- Not only is a Controller responsible for a company's past and present financial situation, he or she is also an integral part of a company's financial future. A Controller must be able to identify and report what areas of a company are most efficient and how the company can capitalize on this information. Team Role: Job would include managing a small team (1-2 people) in all financial aspects of multiple companies which would include; check processing, vendor management, month end processing, account reconciliations, weekly production reports, monthly budgeting/reporting, overseeing accounting procedures and other office staff, helping process payroll, general ledger, income statements, invoices/accounts receivable and other HR items and reporting monthly to ownership. Specific Role: Would include managing and operating budgets for multiple companies and investments, diagnose and evaluate weaknesses in our companies financial (and operational) structure, providing risk management, plan and prepare for long term growth and investments, continue to help build on company strengths in the marketplace, as well as evaluating profitability and creating new ways to increase profit and decrease costs.\n# # ----- FULL_TIME\n# # ----- 72 months of experience\n# # ----- CHIEF\n# # ----- 96 months of experience\n# # ----- JUNIOR\n# # ----- STUDENT\n# # ----- 6 months of experience\n# # ----- LEAD\n# # ----- 48 months of experience\n# # ----- EDUCATION & TRAINING: \n# # High School Diploma/ GED EXPERIENCE: \n# # Preferred- 2 years of hospital registration LICENSES & CERTIFICATION: \n# # None\n# # ----- 24 months of experience\n# # ----- 3 months of experience\n# # ----- 36 months of experience\n# # ----- 84 months of experience\n# # ----- REQUIRED EDUCATION AND/OR TRAINING: High school diploma or general education degree (GED), or one to three months related experience and/or training, or equivalent combination of education and experience preferred. PHYSICAL DEMANDS AND WORK ENVIORNMENT: Standing Continually required to stand Walking Continually required to walk Sitting - Occasionally required to sit Travelling Occasionally required to travel Finger Dexterity - Continually required to utilize hand and finger dexterity Climb, Bend, Balance, Stoop, Kneel or Crawl - Frequently required to climb, balance, bend, stoop, kneel or crawl Talking/Hearing - Continually required to talk or hear Visual Accuity - Continually utilize visual acuity to operate equipment, read technical information, and/or use a keyboard Lifting/Pushing/Carrying Occasionally required to lift more than 50 lbs. at a time with frequent lifting, pushing, or carrying of up to 30 lbs. EEO Statement: Petland is an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, pregnancy, national origin, age, mental or physical disabilities, military or veteran status, sexual orientation, or gender identity status. The above is intended to describe the general content of and requirements for the performance of this job. It is not to be construed as an exhaustive statement of duties, responsibilities, or physical requirements. Nothing in this job description restricts managements right to assign or reassign duties and responsibilities to this job at any time. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.Those applicants requiring reasonable accommodation to the application and/or interview process should notify Petlands Department of Human Resources.\n# # ----- 144 months of experience\n# # ----- Education/Experience: 0-6 months of previous experience preferred Ability to work on single task / procedures / products. Highly repetitive or routine duties, Ability to support 1-2 product lines / customer(s) Normally receives detailed instructions on work Works under close supervision Computer proficiency required Physical Requirements: Perform general physical activities Must be able to stand for up to 8 hours Monitor processes, materials and surroundings Spend time making repetitive hand motion Mechanical aptitude/dexterity and the ability to lift up to 35 lbs Benefits Offered: Comprehensive benefit package including medical, dental and vision coverage; company-paid basic life/AD&D insurance, short-term and long-term disability insurance; voluntary supplemental insurances, flexible spending accounts and employee assistance program (EAP). Sick Leave, Vacation Time, and company-paid Holidays are also provided as paid time off. NEOTech also provides a 401(k) Retirement Savings Plan option with a company match. NEOTech is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex including sexual orientation and gender identity, national origin, disability, protected Veteran status, or any other characteristic protected by applicable federal, state, or local law. NEOTech has a long-standing commitment to maintaining a safe, quality-oriented and productive work environment. We also want all employees to perform their duties safely and efficiently, in a manner that protects their interests and those of their co-workers. We recognize that alcohol and drug abuse pose a threat to the health and safety of NEOTech employees and to the security of the Company’s equipment and facilities. For these reasons, NEOTech is committed to the elimination of drug and alcohol use and abuse in the workplace. Candidates being considered for hire must pass a pre-employment background check and drug test which include screening for illegal drugs and marijuana.\n# # ----- 12 months of experience\n# # ----- 60 months of experience\n# # ----- SENIOR\n# # ----- FULL_TIME, PART_TIME\n# # ----- 180 months of experience\n# # ----- 1 months of experience\n# # ----- 240 months of experience\n# # ----- PART_TIME\n# # ----- 108 months of experience\n# # ----- High School or equivalent\n# # ----- Bachelors Degree\n# # ----- None","metadata":{"execution":{"iopub.status.busy":"2024-05-08T16:24:14.208442Z","iopub.execute_input":"2024-05-08T16:24:14.208779Z","iopub.status.idle":"2024-05-08T16:24:14.228618Z","shell.execute_reply.started":"2024-05-08T16:24:14.208749Z","shell.execute_reply":"2024-05-08T16:24:14.227555Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def extract_experience(text, position_careerLevel):\n    if text is None and position_careerLevel is None:\n        return 'NOT SPECIFIED'  \n    \n    text_concat = f\"{text} {position_careerLevel}\" if text else position_careerLevel\n    \n    # Define regular expression patterns for years and months with \"experience\"\n    pattern_years = r'(\\d+|\\d+\\+?)\\s*(?:year|yr|yrs|years)\\s*(?:of)?\\s*(?:experience|minimum experience|required experience|desired experience)?'\n    pattern_months = r'(\\d+|\\d+\\+?)\\s*(?:month|mon|months)\\s*(?:of)?\\s*(?:experience|minimum experience|required experience|desired experience)?'\n    \n    # Find all matches for years and months\n    matches_years = re.findall(pattern_years, text_concat, re.IGNORECASE)\n    matches_months = re.findall(pattern_months, text_concat, re.IGNORECASE)\n    \n    # Extract numerical values from the matches\n    years_list = [int(''.join(filter(str.isdigit, match))) for match in matches_years]\n    months_list = [int(''.join(filter(str.isdigit, match))) for match in matches_months]\n    \n    # Get the smallest value for years and months\n    years = min(years_list) if years_list else None\n    months = min(months_list) if months_list else None\n    \n    if years is not None:\n        return f\"{years} years\"\n    elif months is not None:\n        return f\"{months} months\"\n    else:\n        return 'NOT SPECIFIED'\n\n# Create a UDF (User Defined Function) from the extract_experience function\nextract_experience_udf = udf(extract_experience, StringType())\n\n# Apply the UDF to the DataFrame columns 'text' and 'position_careerLevel' to extract years or months of experience\ndf_kept = df_kept.withColumn('years_or_months_experience', extract_experience_udf(col('text'), col('position_careerLevel')))","metadata":{"execution":{"iopub.status.busy":"2024-05-08T16:24:14.229950Z","iopub.execute_input":"2024-05-08T16:24:14.230280Z","iopub.status.idle":"2024-05-08T16:24:14.313891Z","shell.execute_reply.started":"2024-05-08T16:24:14.230254Z","shell.execute_reply":"2024-05-08T16:24:14.312715Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\n# Define the function to replace values with exact matches\ndef replace_career_level(value, position_name, position_workType):\n    \n    text = f\"{value} {position_name} {position_workType}\"\n    text_lower = text.lower()\n    target_words = ['junior', 'senior', 'student', 'chief', 'lead', 'intern']\n    \n    matches = [word.upper() for word in target_words if re.search(r'\\b' + re.escape(word) + r'\\b', text_lower)]\n    if matches:\n        return matches[0].upper()\n    else:\n        return 'NOT SPECIFIED'\n\n# Create a UDF (User Defined Function) from the replace_career_level function\nreplace_udf = udf(replace_career_level, StringType())\n\ndf_kept = df_kept.withColumn('position_careerLevel', replace_udf('position_careerLevel', col('position_name'), col('position_workType')))","metadata":{"execution":{"iopub.status.busy":"2024-05-08T16:24:14.315290Z","iopub.execute_input":"2024-05-08T16:24:14.315584Z","iopub.status.idle":"2024-05-08T16:24:14.387923Z","shell.execute_reply.started":"2024-05-08T16:24:14.315561Z","shell.execute_reply":"2024-05-08T16:24:14.386939Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"\n# Define the function to replace values in position_workType based on keywords across all rows\ndef replace_work_type(workType, text):\n    workType_lower = str(workType).lower()\n    text_lower = str(text).lower()\n    \n    # Check if workType is \"other\" or empty\n    if workType is None or str(workType).lower() in ['other', '', None]:\n        if any(word in text_lower for word in ['full time', 'full-time', 'full_time', 'fulltime']):\n            return 'FULL TIME'\n        elif any(word in text_lower for word in ['part time', 'part-time', 'part_time', 'parttime']):\n            return 'PART TIME'\n        elif any(word in text_lower for word in ['work from home', 'remote', 'remotly']):\n            return 'REMOTE'\n    else:\n        return workType_lower.upper()\n\n    return 'NOT SPECIFIED'\n\n# Create a UDF (User Defined Function) from the replace_work_type function\nreplace_work_type_udf = udf(replace_work_type, StringType())\n\ndf_kept = df_kept.withColumn('position_workType', replace_work_type_udf(col('position_workType'), col('text')))","metadata":{"execution":{"iopub.status.busy":"2024-05-08T16:24:14.389276Z","iopub.execute_input":"2024-05-08T16:24:14.389639Z","iopub.status.idle":"2024-05-08T16:24:14.436845Z","shell.execute_reply.started":"2024-05-08T16:24:14.389606Z","shell.execute_reply":"2024-05-08T16:24:14.435743Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Load the spaCy English model\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Define the UDF to extract required skills from job descriptions\ndef get_required_skills_udf(job_description):\n    # Process the job description using spaCy\n    doc = nlp(job_description)\n    \n    # Initialize a list to store verb-noun pairs\n    list_of_verbs_nouns = []\n    \n    i = 0\n    while i < len(doc):\n        if doc[i].pos_ == 'VERB':\n            temp = [doc[i]]\n            i += 1\n            while i < len(doc) and doc[i].pos_ == 'NOUN':\n                temp.append(doc[i])\n                i += 1\n            list_of_verbs_nouns.append(temp)\n        else:\n            i += 1\n    \n    # Filter out verb-noun pairs with only one word\n    filtered_list = [pair for pair in list_of_verbs_nouns if len(pair) > 1]\n    \n    # Convert the pairs to strings\n    list_of_skills_to_string = [' '.join([token.text for token in pair]) for pair in filtered_list]\n    \n    return list_of_skills_to_string\n\nget_required_skills = udf(get_required_skills_udf, ArrayType(StringType()))\n\n# Apply the UDF to the DataFrame column 'text' to extract required skills\ndf_kept = df_kept.withColumn('todo', get_required_skills(col('text')))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-08T16:24:14.440189Z","iopub.execute_input":"2024-05-08T16:24:14.440556Z","iopub.status.idle":"2024-05-08T16:24:16.071471Z","shell.execute_reply.started":"2024-05-08T16:24:14.440524Z","shell.execute_reply":"2024-05-08T16:24:16.070389Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"csv_path = \"output1.csv\"\n\nwrite_df_to_csv(df_kept, csv_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T16:24:16.072574Z","iopub.execute_input":"2024-05-08T16:24:16.072903Z","iopub.status.idle":"2024-05-08T16:46:46.288472Z","shell.execute_reply.started":"2024-05-08T16:24:16.072872Z","shell.execute_reply":"2024-05-08T16:46:46.287474Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"DataFrame written to 'output1.csv'\n","output_type":"stream"}]}]}